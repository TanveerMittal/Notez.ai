Would you. What it does anybody have any questions or comments to get us started. A new nurse SIP of coffee. Many people here. trickle in. Staying up too late. sounds like somebody was having a conversation alrighty let's get started, then today. As we talk notation. This is going to be a tool that we use in this class and that you'll use in the future it's a it's a good sort of measurement of certain qualities of algorithms. You could talk about the basic, the main thing you're talking about is the runtime of the algorithm you want to use as a tonic notation will give some motivation for why. i'm so it's mainly. At least for us it's mainly. used for algorithm. analysis. But you will, but if you're a mathematician you'll you might use it in. In approximating things or. Right so also used. to approximate. math formulas. And maybe maybe we can look at a few of those at the end of class. Okay, so we're gonna figure out how to use it manipulate it compete the runtime of sorting and searching algorithms that we talked about last time. learn some tricks for computing run times of loop based algorithms. learn some tricks for computer run times of recursive algorithms I imagine we won't get to this really today, we may get to this loop based algorithms but the recursive algorithms will probably have to wait till next week. Okay, so linear search versus binary search we've already seen these graphs and I really want you to understand where they come from recall. That linear search. And comparisons. On input. Of length. And, in the worst case. binary search. I forgot exactly what it was, was it the ceiling of log base to have n plus one. Day and really the essence here, the thing that you need to kind of understand is that the function. y is equal to end will grow much faster than the function y is equal to log in. And you can kind of see it in these graphs. This first graph only goes up to 17 which is 16 really. And there is a there is a big disparity between these things, but once you get really big like around 120. You can see that you know the green line is going to keep on growing like that or the red line hasn't even hasn't even reached 10 yet. right and it won't reach 10 until around 1000 when when you get to the 10 is around 1000 so just to kind of give you a sense that this this log function is still growing. But that linear function is just growing way faster and it's going to be like this smaller and smaller fraction of it until once you get big enough it's going to kind of be totally insignificant and you won't be able to tell the difference between it and the X axis. Okay So how do we say this mathematically we say binary search is ask them topically faster than linear search and then we talked about this last time, but just to kind of reiterate the time. The time function, the function. of time of binary search. Is as them topically. slower growing. Then. The function. linear search and we saw that in the grass linear search the graph is growing faster right and grows faster than login, but it has an inverse relationship with speed right because. Speed is generally equal to right right distance over time, or something like that the. The The important thing here is that speed and time are inversely related so when we talk about speed. we're going to try to be really clear if we're talking about the run the function of time, the speed that the function of time grows or the actual speed of the algorithm. Usually, when we say speed we're talking about speed of the algorithm so just to kind of make sure that you can distinguish those. Okay, so. Okay So how do we actually. Talk about this mathematically what is the what is the mathematical fact that we can base all of this on. Okay, so let's say t of bs of N, is the runtime of binary search for a list of size and and T of Ls of N, is the runtime of linear search of a list of size and so, if we take the limit. Of one of those run times over the other you'll see that the limit goes to zero because. We essentially have. We essentially have like a log base to have n plus one, the ceiling of them divided by and right and. I won't go. super in detail right now but we'll do a little bit more detail of things later, but the idea is that n grows faster than login so this thing is going to go to zero. percent goes to infinity and the way that we. Instead of writing this whole thing out all the time we say that t of bs. Is. Little oh. of tea of Alice and what does that mean that means that the that just means this thing that I circled. Or you know you can say it in a bunch of ways and we'll give you a a more mathematical definition of these things in a minute. Okay, so um. Other asset classes and notations that we're going to be using in this class there's big data. there's little oh. Bingo. And there's big Omega. Okay, and i'm. Here are all their definitions in terms of limits, but we're also going to look at a different definition that uses constants. Okay, so F and F is big data of G this first one, this means that F and G grow at you know at a similar rate, the only thing that's different about them is some constant multiple. And the way that you can see, that is if they're. If they're ratio. approaches some constancy, then that means that as n goes off to infinity they're really only like a constant factor apart. We already saw little Oh, that means that it just goes to zero. And Bingo is sort of the the Union of data and little oh. So, in order to in order for me to be big data of G that basically means that either F and G differ by a constant or. The function G grows faster than the function F. Okay, and then big Omega is the opposite of big. So F is big omega of G also oh yeah I have it right here there's also means that just G is big of F. Okay, so let's look at some more. motivation, why are we doing this in this class so far we've been doing a lot of counting right. And we've been using a bunch of different methods and our goal was to compute the exact number of these objects. we're going to shift gears here and instead of counting the exact number, we want to count an approximate number so. We want to kind of talk about how do these sequences grow what, what can you expect from them are they going to double in size every you know after every iteration or are they going to grow linearly or logarithmically and we're going to try to use this notation to compare them. Okay let's look at a poll. let's consider these two functions. n squared and three n squared. Now, what happens to n F of N, when you double the input size and what happens to G event when you double the input size. Some good answers here. We got a is the most is the most answered one but D is a close second and then we have C and b so let's do an actual experiment and see exactly what happens. Okay, so. F C doodle. let's say F of two is equal to for right now, if I double the input. Ever for is equal to 16. About je. je have to is equal to 12. And if I double the input g of four is equal to. what's three times 1648. What happened. they're both multiplied by four. Right, so the behavior of how they grow if you kind of talk about it in this way, what happens to the function if you double the input size or what happens to the function right if you do a certain operation on the input size. notice that these things do the same thing right if you in terms of this. In this problem. And so, that means that there. They kind of grow at the same rate in a way, in a sense, right certainly G event grows faster than F of n if you're just talking about like the calculus rate of growth, but in this class we're going to consider them as growing at the same rate because of this sort of argument. Okay, so since F and G sort of behave Similarly, when you increase the input, I should say, increase the input by. Car. By a factor right. We say that F and G grow at the same rate or F is big data of G F of X is big theta of gn. informally if F G event grows, just as fast, up to a constant up to a car, I should say, up to a constant multiple. Then F, then we say F is big data of G using limits, what does this mean, this means that, as you go off to infinity they're just going to be a constant factor difference so limit of F event over g of X is equal to see that means right for. and very large. Well let's do capital and for capital and very large F of n. Is around C times G event. Right that's kind of what it means and and that you can sort of see that, in the previous example, one of the functions was n squared the other one was three m squared so you could already see that one of them is a constant factor multiple the other. Okay, so see has to be a constant greater than zero because what happens if see a zero. Then this. This equation doesn't work right then you're just saying after of n is approximately zero but that doesn't really make sense, because we're we're considering to be increasing functions. Okay, so here is a more formal way to define it. F is big data of G means that there's constant C and C prime NK such that F of X is less than or equal to see times G event and G event is less than or equal to see prime times F of an for all and greater than or equal to care it's kind of like you can. You know if you have these two functions and, if you want one to kind of beat the other there's a constant that you can multiply. And then that function will always be bigger or you can multiply the other one by function and that function will always be bigger so it's kind of like you can you can make one function, bigger than the other just by multiplying it by a factor that's what this is saying. And this is saying for all and greater than K this just means. kind of means as and goes to infinity. Right it's like look far enough down and eventually one's going to take over the other. Okay let's go to big big Oh, maybe is the one that you heard about the most, it is a very useful when we're talking about run times, or even like the space complexity of an algorithm. is more or less what we consider to be like an upper bound so big oh is. More it's it's a. it's kind of like a loose loose definition would be kind of an upper bound, and I want you to use upper bound as a definition, but think about that as kind of the way we're thinking about big. So big oh is only kind of one direction of big data it says that there's constant C and K, such that F of X is less than or equal to see times g of n for all and greater than or equal to K so it's just saying that. there's always a way to multiply g by a constant so that God will take over F forever, but it's not it's not too it's not the two ways like big theta right there's there's nothing in it that says, I can multiply F by a constant to get bigger than gene that might not be possible. Okay, so big O beans g of and grows, just as fast or faster than F of n so kind of informally. g event is an upper bound. of Africa and. i'll put it in quotes because it's not exactly what it means, because you know there there's this there's this thing, where you can multiply by constant, I guess, I should say informally see times G event is an upper bound for of F of n. For some constant. See and for n big enough right. and greater than or equal to K. I mean that's really just what what that previous definition was anyway. Okay, so you're going to see. A few different. notations you'll see this. Inclusion set inclusion are what we call it element of and also equal signs which one is appropriate to use they're both fine both. are acceptable. I tend to use the equal sign, although the element sign, I think, is sort of more correct in a way. But the equal sign is more common, so you can use either one, and if you see me use one or the other. Just consider them to be the same in this. In this this type of lesson. Okay questions about that. Oh wait what is mathematically what is the definition. Remember, this means that. There exists constancy and K. Such that. What does it. Ever van is less than or equal to see times g. For all and greater than equal to Cain and I should say something about this, this. is assuming. F and G our part positive valued functions. There is a definition that you can have for functions that are positive or negative and essentially what you do is you just. You just put absolute value signs around them. So when we talk about growth what we're really talking about is. Growth as distance away from zero so really kind of like as it grows into the positive direction or if it grows into the negative direction. There that's kind of the growth rate that we're talking about but we're really only going to look in this class we're going to look at a positive valued. positive value functions. Okay, so here's the here's the here's the definition so let's say I have an F and G. Is. F of n. g of n. yeah I think so. Okay, so. If you say yes. Then um. What. are appropriate. values. For C and K. For see is equal to for. me, what about K. K is equal detention work. Okay, so with these constants. You claim. That F of X is less than or equal to four times g of n. For all and greater than or equal to 10. Is this. True. And how do you show it. See the hundred K is equal to 100 if you want to be really safe okay good so. Is this true. Yes. How do you show it. Really kind of the best way to show this particular. set of constants is to use induction. Professor. Yes, can we just simply minus four and square. Use foursquare and minus three squared plus two N and prove that like. The proof that the remainder like say is n squared plus dwayne is always greater than or equal to 04 K is equal to or greater than or equal to 10 like. Okay, good I don't think. You can use like algebra right. So induction or algebra. or even calculus right. yeah that's a good that's a good way to do it right you'd say i'm. Here let's do let's do like a more formal proof. I like that, because that'll be good to to write on here for everybody, I think, to kind of see that. Okay. Okay, so proof. That. Three n squared plus two and is less than or equal to four and squared for all and greater than or equal to 10 right. So. You can do it like this right three and squared plus two and. is going to be. Okay let's start like this, you can say to n is less than and squared for all and greater than or equal to 10. Right. Because two times 10 is 20 and 10 squared okay that's what we have to do right let's be very formal here. To has got to be less than or equal to end right because and is greater than or equal to 10 multiply both sides by n to n is less than or equal to n squared then add three and squared to both sides. And you get three n squared plus two. induction only works for integer value ends not real numbers right, and so in this class when we talk about these functions were usually going to be working with real us with me with integers but, as you could probably already see. When we take these limits we're going to kind of consider these functions as real functions functions of a real variable but some functions are more integer valued and it's going to be harder to do that limit and will experience some of those a little bit later. Okay. So why are we using these two different things, the the element symbol and the equal symbol, the element symbol and Why did I say the element symbol is a little bit more. Correct to use it, because this this notation big of g of n is actually a set it's a set of functions. Would that be as efficient proof say for homework, or we need to explain that that would be this would be great, this is a great proof is there something wrong with it. Lack of words, I mean if you wanted to you could say. By. The fact, if you want me to put these I can put these. And is greater than equal to zero to 10. I guess, this one is assuming. Oh, assuming n is greater than or equal to 10 so and is greater than right and is greater than zero so you can multiply and by both sides right, this is. I mean. This kind of like simple algebra going to just assume that we all are familiar with with this, so if you add. Something to both sides of any quality than the inequality doesn't change. Can we use a graph to justify it no. You cannot use a graph to justify these things. You can't. use a graph. or table. You can use a graph or table to kind of give you an idea, but the proof has to come from. A more general proof the reason you can't use a graph or a table is because these types of objects don't show you how and behaves as n goes out to infinity right because they're finite objects that you can only really look at finite number of values. limits, you can use limits yeah you can use limits. we'll do some of that a bit later. Okay, so back to this thing big of G event is actually a family of functions it's a set of functions, and so, if i'm saying that F belongs to the family of big of G event, that means that. F is in that set, but it also has that other meaning. In terms of limits that we've seen and also in terms of these constants name some functions that are in the family of big oven square will certainly and squared but what else. Okay, good n anything else. And login. Okay, good one million n squared we'll just do 1000 n squared. Five n squared. cosine in. cosine in. Well i'll just put a star there but it's true but we're gonna. We are mainly. going to. focus on increasing functions. But is true, that is true, which. I guess one is not an increasing function but I guess non decreasing functions. Okay square root and good and to the 1.5 right. All quadratic polynomials right so maybe like three n squared plus. 80 and plus seven rings things like that. Okay, one over and again. it's true we're going to move mainly do these for increasing functions, there is a whole. kind of other branch of as atomic notation where you talk about decreasing functions like one over N and one over n squared which. Which is really useful in mathematics, when you talk about approximations or not going to really spend a lot of time on that. Okay little O notation informally if F g of in gross strictly faster than F of, and then we say that F of n is little of g of n. And it's kind of saying that no matter. How much you multiply F of n by G event will eventually take over doesn't matter how big of a. Of a multiple you multiply ever been. And mathematically we can define little Oh, in terms of Bingo and big data. So it's all of the functions that are in Bingo and not in big data another way to say that in set notation would be Bingo or little of g of n. is equal to Bingo of g of n. minus data of G event. Or, this is set difference. And so what else what other kinds of things, what other kind of set theoretic things can we say we can say that big of g of n. is equal to little of g of n. Union FADO grn. And little oh gee have an. intersect theta jovan is empty. Right you can't you can't grow at similar rates and strictly faster, at the same time okay any questions about those. Okay, so our goal with these algorithms is to design algorithms who's runtime as as small as possible, up to the order up to the ask them topic notation up to the ass and tonic notation class after class. If a runs in time ta and be runs in time TB, we consider a as i'm technically faster if ta is in little tip, this is what we saw with binary search and linear search. So how do you determine if F of an his big old G events, so this is what you all were asking a few minutes ago. Okay, so approach, one is to look for constancy and K directly then prove. They work. Using. algebra. calculus. or some other. Some other kind of like technical argument. approach to we can use some of these properties okay so domination, if you know that F is less than or equal to G for all N, then you know that F is big oh gee I mean it just kind of. A consequence right, and the reason behind this is because. You. can set see equal to one and K equal to one, so there exists the C and K that work in this situation okay trans activity if F is big of G n G is big of H, then at this big old age, and this is. You know this is, this is a nice exercise to try. To try to prove using the definitions okay activity and multiplicative it if you multiply F and G, by the same function, then, if F is big of G F times ages, big or G times age. Okay, some is the maximum this is kind of like a funny one but it's very useful when we when we're trying to simplify these things is that if you have a some. Then. Only the dominant term is important when you talk about bigger so. Only consider. The dominant term. And lastly, ignoring constants because if you if you're talking about you're allowed to multiply and the function by any constant you want it doesn't really matter what the constants are. For any constancy a constant multiple times F is Bingo. So one kind of way to. organize this is look at the terms, one by one drop all the constants then only keep the maximum or dominant value. Were dominant term. Okay let's do an exercise. Whatever to my pole. What could be in the following expression. Okay, good share results okay good we're saying he more than one of the above, which ones. and Cuba and square. Thank you, thanks Square. Okay, good oops. So how do I kind of evaluate that. You can kind of drop all the constant so three and to come, all the constant multiples of each term and then keep only the most dominant term which is n squared so n squared. it's kind of like you can you can simply sort of simplify that expression down to n squared that's the class that you're looking at now and squared is. Big of n squared for certain but n squared is also big of n cubed right because n cubed dominates and square this is from the fact that n squared is. n squared, of course, and this is from the fact that n squared is little of n cubed. Right and so remember that big ego is the Union of these two things so either one is fine in big oh. it's kind of like n squared is sort of like a better answer be in a sense of sort of better it's tighter. And so we're going to try to get the tightest answer, we can but sometimes it's not going to be as easy to to just see what the tightest bound is but we're going to strive to get the tightest bound for each one. Okay, how about this one. Is three to the end big of two to the end. Okay, so most most of us are saying, be no is not and that's correct, how do you show, something is not big of something else. I think if the functions that you're dealing with our continuous functions like exponential is are the easiest way to do it is with a limit argument so. oops. limit as and goes to infinity of F of an overview of n. is equal to the limit as X goes to infinity of three to the end divided by. Two to the end. right which is equal to limit as X goes to infinity of three halves and a half to the end, and if you all know how exponential functions work if the base is bigger than one than the exponential function will increase to infinity. Right now, remember our our limit definition of big O FM is big of G event, if, and only if the limit goes to a finite constant and infinities not finite therefore. Right. Therefore. Is not big of God. Another way you can do it is to show. That there is no common sense or there are no Constance. C and K, for which. hand is less than or equal to see G event for all okay. and be let's do this proof to because that might be. Okay, we want to show. That, what is it three to the end is not big or two to the end, I mean the limit argument was perfectly fine, I just want to show you a different argument, so that you can kind of choose which one you like better if you're asked to do this. So claim. There are no Constance. C and K, such that. The end is listening equal to see times to to the end. For all and greater than or equal to K. How do you prove something like this, or what does anybody have any ideas of what kind of proof technique would be useful here. Proof by contradiction good so suppose. By contradiction. That there exists. C and K, such that three to the end is less than or equal to see times to to the end for all and greater than what's OK now what goes wrong here. We can rearrange this equation right. Right well yeah there is no such see right okay good yeah we can rearrange the equation, to be three over two three to the N over to to the end is less than equal to some constancy right. For all and greater than your equal to K. And maybe you will you'll start to see why this is wrong right, you could say choose. And to be large enough. So that. or let's say let's say choose and equal to begin to be large enough so that three to the end over to to the end is greater than see. right since three over to to the end goes to infinity you can find some some some value of n. So that it just kind of passes it, this is kind of what it looks like is that you have some. You know this is going to be the function y is equal to see right. And here's the function y is equal to three over to to the end so. Since it since it the that function goes off to infinity it will it will surpass that constant at some point. All right, let's move on Okay, so you can use these limit arguments they're usually a lot easier to use than doing a proof by contradiction. But it really only works if the functions that you're talking about our continuous functions, the functions are not continuous then it's harder to do that. Okay let's show that and login squared is Bingo of and squared and we could show this in a few different ways. First let's look at their graphs. This is not a proof, but it is a. It should maybe give you an idea of which one grows faster. So we have n log n squared is the is the maroon line. and end of the three halves is the is the blue line now, it looks like. Around. I don't know 75. The blue function takes over the maroon function now is this enough to show that it will take it over for forever no but it gives you some some evidence that maybe it would, and then you can. You can plot all the. values and and notice that n log n squared is bigger than n squared n right as you go until you get around. 70 to 80 that's when it shifts. And you'll notice that and squared of and dominates and login squared after that. Okay, so. How do we actually prove it. I thought I had a. i'll show you a few different ways that. I. will accept as valid arguments. Okay, so you could use a limit. Okay, so limit as n goes to infinity of. What was the first thing. And login right. And log of n squared divided by. n Square and. So you can. Factor out the ends. You can bring out the to write blog and divided by square root and. How do you do this limit. You use locales rule right, so this is going to be limit as and goes to infinity of two times one over n divided by. One half and the negative one half. Right, so this is equal to limit as and goes to infinity of. it's going to be for. times and the negative one half, which is equal to zero. You first use a property that have logged to take out a constant yeah so it's easy okay good so that's good that's one way to do it. So um you are allowed to use. you're allowed to use the fact that. log and is. is going to be always less than and you're allowed to use that fact Okay, so if you're allowed to use that fact then and log. What is a better way to do it, I think the limit way is the best way. I guess what other kind of things, am I allowed are we allowed to you is. we'll have to kind of see. there's kind of like a hierarchy, that it will talk about so maybe we'll come back to this one in a minute. Okay, so here's some exercise, how do we prove these things. prove or disprove is n squared big of two to the end true. You can use a limit argument. or algebra right. This is false. You can also use the same limit argument. or proof by contradiction. Okay, this one is true, you can use kind of the you can use a limit argument, of course. Or you can use. kind of the rules. Of Bingo. Right, the one where you. Are you take away the way you only keep the dominant term okay and login is Bingo of n squared this is true. Again limit argument. or algebra. or induction okay how about this thing. and choose three is not a continuous function, so you can't really use a limit argument or can you. Or can you use the rules of big. You can use a limit argument, so how would you do it. Use the formula right so convert. and choose three to be equal to, and times N minus one times N minus two divided by three factorial. If you multiply this whole thing out right. Only keep. The dominant term. Which is n cubed. So you can use like the rules of bigger. Okay, how about this one. So Ben is and fibonacci number. Again, this is not really a continuous function, so how would you prove this one induction I say this, this is one is best proven by induction. or use bernays formula sure. Okay, so some exercises. If I know that the. If I know that the limit of Fo virgie is 20 then, what do I know is true. So we say two of the above, mostly which are we talking about. ANC. This is a trick question. Because if a MC or true that implies that B is true, so a B and C, are all true trick question. questions. Okay, how about this, if I know that the limit. If I know that the limit of Fo virgie is zero then, what do I know it's. Is this one, a trick question. This is to have the above which to is it it's going to be. Smaller and bigger good D and a. Great questions about that. So families have some classes, we already kind of looked at this but let's just do a few more so in big and cute you have. n cubed anything any kind of. Third degree polynomial but you also have smaller things like n squared and one log and Square and. And Q, you know, three n cubed plus for n squared stuff like that. Okay, what are the functions of the family of big data of n cubed what is kind of the main thing you need in that function. You will need to have and cubed kind of needs to kind of grow as n cubed so. Any polynomial. Of degree three. Right, but other things like n choose three right that's going to be big state of n cubed. Even things like three n cubed plus and login frank plus. square root and. Okay, what about the functions that are in the family little event Q now you can't have any of these n cubed things right it's everything that's in big ago but not in big data so things like n squared plus and right and login. Even like in to the two point. Like n squared times square root of X, which is equal to, and to the 2.5 things like that I fractional exponent are allowed, and they you know they're still kind of underneath that and cute. Okay now what functions are in the family big omega of it and cute well, we have. All of these n cubed guys right and cubed plus eight n cubed plus n squared what else. To to the end all the exponential right through to the end. Any polynomial of the bigger degree. into the. 18 plus and square. In factorial and to the end right, so this is just kind of unbounded right all of the functions that grow much faster. Okay, so i'm ranking growth rate of common functions, and so this is what I was kind of alluding to before is that. Your you're. you're allowed. To use this. As an argument. Okay, so. Basically, that like login is going to be less than and any any power of login is going to be is going to be big of an. And it's going to be big of an login so you can use these as you as you wish. Also, that and to the Alpha is big of. Have into the beta. If, and only if. alpha is less than or equal to beta and even with extra elements, you can use the fact that a to the end is going to be bigger have been to the end if, and only if a is less than me but a lesson to be. You can even throw something in here too, which is and to the epsilon where epsilon is greater than zero. I guess it, for it to be less than linear it would be. Greater than zero less than one. Okay, good any questions or comments. Okay let's in the next 10 minutes or so we'll talk a little bit about runtime performance and where we're going with all this awesome topic stuff. So an algorithm is a problem solving strategy as a sequence of steps examples of steps are comparing list elements we talked about this with the sorting and searching accessing a position arithmetic operation for small numbers. And when I say small I mean small enough to fit into a memory size. memory word sighs. Okay, so a single step depends on the context. How long does a single step take. It depends right what kind of computer do you have what how old is your computer you know when was it made who made it some computers do some steps faster than others right, some are much more. Faster much faster at matrix operations, for example in some are more faster at manipulating arrays so it depends on the software and the hardware we're just going to kind of skip through that so the time our program takes is going to depend on a few things first of all, the input size. The number of steps that algorithm requires and the time for each one of these steps in our system. Now this is something that varies. By. machine the machine that's performing the algorithm will vary these first two things input size and number of steps the algorithm requires. Those don't vary, those are always going to be fixed based on the algorithm so Those are the things that we're going to focus on the most because we don't want to have to analyze the runtime of every algorithm for every single machine. Sure it'll give you a lot more information and you'll be able to kind of figure out the time but. it's not as useful. Because, as we grow, you know technologically our computers are going to get faster they're going to be able to do things do single steps faster. And so I don't want to have to compute the runtime every time a new computer comes out it's much better to have an approximate idea of how that how the algorithm time grows, based on the input size and just apply that to all machines in general. Okay, so um I read this article i've been teaching this class for a few years now, so this was back in October 17 2017 and. I think computers have even gotten better than this, but on that date, the fastest computer. was a Chinese supercomputer that could compute 33,860 trillion calculations per second. So let's say that the. let's say that you have access to the supercomputer for an entire day 24 hours if you have an algorithm that runs to to the end calculations. On an input size of length and right on. Then, how big can your input be so that the calculation ends in 24 hours. mean you're gaining access to this amazing machine I could do all these calculations. You want to do as much as you possibly can, the biggest input that you can. yeah okay i'll end the polling share results okay good so be be is the right answer so yeah like like you saying in the chat. To the 10 is small right it's around 1000 but to the hundred is a really, really big number, and so the answer is, be the exact answer is something around 71 and how do you get that i'll just kind of give you a. A fast way to compute it So what is this number it's 33 860. Right and trillion is 12 zero so 1-234-567-8910 1112 Okay, so what you want to do is take the. This can do this, many calculations in one second so. How many calculations, can you do in 24 hours, where you're going to have to multiply this by. There are 60 seconds in a minute 60 minutes in an. hour. And 24 hours. And that comes out to be. Fine. 33 times. it's about. 2.8. Something. And then 123456. Something like that. So you want to take the log base to have that thing Oh, maybe 2.2 point nine yes sorry something like that. You want to take the log base to have that thing what you do is you count the number of. pairs of three zeros 1234567 and then you estimate the the log base two of the leading term which is. log base to have two is one, so this is around the the log base to have this number is around 71 like you said. Okay, so that I hope that that kind of gives you a sense of of really bad complexity functions like to to the end. Even if you had access to a computer like this, you really can't push your input size farther much farther than 71 right, and if you wanted to get up to 100 you know what that. That wouldn't just mean 30% more time. The input, the time doubles for each. Each time the input size increases by one, so it can get out of hand and it. Have you read about this kind of exponential growth it's hard for our human minds to really wrap our heads around how fast it grows because we're used to kind of seeing things grow linearly. Okay, so other really bad complexity. classes would be. To to the end to end shoes and which, if you're interested is around four to the end, or I should say, actually, we could we could even do this like this is big theta of four to the end divided by Square and. We have n factorial course that's rude that grows, really, really fast and to the end grows fast okay. So we just have a few minutes left. um. Let me just say one thing about logs and then we'll call it a day. you'll often see if the runtime algorithm has a login it's usually a log base to because we're usually doing something where we're dividing out by to a bunch of times until we get down to the base, just like we did with binary search. We usually just say la big of login or big O n login and we leave out the base. What what base are we assuming is on the log. The answer is. It doesn't matter. And maybe you all, can do figure this out as an exercise. about why. Okay, so i'll stick around for another 10 minutes or so. And answer any questions. Okay, see you all next week.