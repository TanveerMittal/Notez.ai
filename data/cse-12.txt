starting to record anybody have any questions or comments, before we begin. alright. So we're gonna continue the discussion of algorithms and just kind of some basic analysis so last time we did stuff with. intuitive algorithms loop based algorithms and saw that often using a looping variant is a great way to show that they're correct or even just to kind of figure out what they do you know and and use that as like a way to to study the algorithm recursive algorithms. we're going to learn about how to design recursive algorithms and sometimes you can design a recursive algorithm that is. it's kind of like based on a loop based algorithm so we'll do. And then. Talk about recursive algorithm correctness now, this is still using induction. But as you'll see. The recursive algorithm or recursive algorithms in general they really lend themselves to us induction it's kind of like how. How they're designed is with induction in mind you kind of assume that the answer is going to be, or that the algorithm will work for smaller cases and you use that to. design the rest of the algorithm. Okay, then we'll take a look at runtime which involves. Solving. A recurrence. relation. And then we'll take a little little detour into merged sort and merge merge store is a example of a recursive algorithm that has the that also has the classification of being a divide and conquer algorithm so we'll talk about. divide and conquer. And when we when we do the runtime of a divide and conquer algorithm we're going to use something called the master theorem okay so let's get started. Last time. On Tuesday we looked at this particular algorithm it counts the number of don't even have the. Have the problem specification it counts. The number. Of 00 occurrences. Right and it's pretty straightforward you basically just scan through and. Every time you see a new occurrence you increment that count, by one. Okay, how can we change this into a recursive algorithm does anybody have any ideas. Okay, so okay good so in a recursive algorithm you, you always need to have base cases, because if you don't have those then there's no way for the algorithm to know when to stop. Okay, good so yeah this is kind of the idea is to check the first two characters if they're a match right if they're an occurrence of 00. Then you then you have one occurrence in the beginning, if they're not then you have zero occurrences in the beginning, and you add whatever whatever result you get to the recursive call, starting from the second bit, let me show you how that works. Okay, just like we said. This is called the base case. Remember, I was saying recursive algorithms really lend themselves to thinking about induction thing about the algorithm inductive Lee. And so, with induction you need base cases recursive algorithms you need base cases, so if n is less than two there's no possible way that you can get even one occurrence. Otherwise. If you get a occurrence in the first two bits then return one that's from this recurrence plus. The the same algorithm applied to be two through bn how do I know that that will reliably count the. Number of 00 occurrences. Well kind of at this point, you don't really know you need to use induction to convince yourself Okay, otherwise just return. The number of. You know the the recursive call on B2B end without adding anything because you didn't have a. pattern match in the beginning. Okay. So this example shows that essentially the same algorithm can be described as iterative or recursive it's not always so simple it's not always so easy. But describing an algorithm recursive Lee can give us new insights and sometimes lead to more efficient algorithms and also. efficient in terms of runtime. But also sometimes. leads to. shorter algorithms. And we're not going to really. talk so much about that in this class having an algorithm be elegant and using few lines and stuff like that, I mean it should probably be something to think about right you don't want your algorithm to be super long and and confusing so recursive algorithms sometimes are able to. make it a little bit more succinct another thing that I like about recursive algorithms. As you'll see here is that we don't have to worry about keeping track of the indices like we did here, and you have these indices, and where you are in the thing, and you know it gets worse and worse, the more loops that you have so. recursive algorithms kind of function all those indices in their recursive calls kind of like behind the scenes, so I kind of like that about them. It also makes correctness proofs more intuitive. You don't. need a looping variant. And as you're going to see the induction for the correctness proof is pretty much just the algorithm it's. You just kind of going through it so. So this is what i'm saying induction and recursion induction is approved strategy where you prove the base case and then, how do you to prove the statement of true about n plus one, you need to assume as true for and right. recursion as a way of solving a problem where you give the base case and in order to solve a problem of size and plus one you. You use the information of solving a problem, size and so they're they're very similar concepts, you know they do completely different things, but they kind of rely on the same fundamental. Okay, so here's the template for proving a recursive algorithm correct. um you use induction on N, which is the input input size. The base cases of the recursion usually are the base cases of reduction of induction they're usually just written right out in the algorithm that you can just say this is the base case, and this is why it, this is why it is correct. Right see why is it the correct answer all right. Sometimes you need strong inductions sometimes you need regular induction but you just do a regular kind of induction. And here's kind of the the key of the proof is that the induction hypothesis allows us to conclude that the algorithm is going to be correct and each one of those recursive calls, so you can kind of like replace the recursive call with what the algorithm is supposed to return. And when you're proving it, you can just you can just use that for free because of induction see i'll tell you what I mean by that. Okay inside of the inductive step. express what the algorithm does in terms of the answers to the recursive calls to smaller inputs so usually this is. is given. problem. Right, the problem says, I want to algorithm to return this thing then you say assume my algorithm returns this thing now show that it returns that thing I sometimes it kind of seems a little circular but just trust that we are using induction here. replace the answers for the recursive calls with the correct answers, according to the problem, this is the inductive hypothesis we're really just going to be replacing them with what they should be. And then show that the result is the correct answer all right let's let's actually get to work here, prove that for any string. be one through bn count double rack be one through bn is equal to the number of places the sub string 00 occurs hey proving this claim by induction let's get started. base case and is less than two that means and zero, and it is one or in a zero or and as one and zero, the only input is the empty string which has no substance, so the algorithm return zero, which is correct. And as one the input is a single bit, so it has no two bits i'm strings therefore the algorithm return zero, which is correct, usually the base case is is. pretty simple to state, you have to make sure that it agrees with what you want the algorithm to do. Okay inductive hypothesis. For some K greater than or equal to one assume that for any input of string of length K count double rack be one to bk is equal to the. number of places the string 00 occurs, we want to show that it's true for any input of length K plus one Okay, are we using strong induction or regular induction and why. we're using regular induction and that's because you your original input. Is. length. And, and each one of your recursive calls is of length and minus one. So, since you only going back once one or one thing. Right any questions about that. Okay, so let's do the inductive step. you'll often see that the inductive step. You have to do a few cases. it's not always the case it's not always the case that you have to do cases but a clue that you have to do cases will be from the conditional so. notice that I have this if statement. If something happens then return this recursive call otherwise. return this recursive call and so those are my two cases and an IT I need to show. That it works in both cases and it'll work for the entire algorithm okay so case, one is that you do have an occurrence. again be one zero. And the out what happens in the algorithm. Some. things happens in the algorithm is you're going to return this value one plus the result. So one plus this recursive call is going to be equal to one plus the number of occurrences of 00 in this thing in this input. And now that one refers to the one occurrence of 00 in the two first positions. So the kind of the magic here happens when I replace the recursive call with what it's supposed to. Sorry, my my volume was. Was anybody trying to talk. To somebody. Okay, I just muted them all okay thanks okay so case to you can maybe just kind of go through this pretty easily. If B one and B to our are not an occurrence, you can essentially. throw away. be one right just get rid of that because it's not going to contribute to any of them so that means that the number of occurrences of the full list is equal to the number of occurrences occurrences, starting at be two. And by the induction hypothesis, it will count that one correctly. Okay, any questions or comments. Okay, in conclusion, we showed that the algorithm was correct for inputs of length zero and one and we show that is correct, for inputs of length K, that is correct, for inputs of link K plus one by induction that means it's it's correct for any input size greater than or equal to zero. Now let's talk about runtime How long does this algorithm take. We can kind of attempt to do the runtime analysis by by labeling each line of code right. So this thing is a constant time operation, just to check to see if it's big enough. And then. If you have here then return count double rack of this, so how long does this take. well. In order to know how long that takes. I need to know how long the algorithm takes so it's kind of like this circular logic it's like in order to. calculate the runtime I need to know what the runtime is already. And so we're going to use recurrence relations to kind of get around this fact and and solve them with the techniques that we did in the first few days so different cases come from the non base case return statements, the different cases come from the if statement. yeah there's two different recursive calls that happen in two different conditions, so you have to make sure that they are. They both work. doesn't make sense. Okay. So how do we get around this. Well let's use a technique that we talked about the first few days is when you're talking about counting something, because here we're really trying to count the number of. sort of computer steps that the algorithm takes when you're trying to count something you don't really know what it is yet often it's good to name it something so we're going to name it. To, then let the vendors that represent the time the algorithm takes now this this term, time is a little vague because different computers will take different times. So we're going to be using sort of kind of constants that we don't actually know their exact answer we just know that there are constant and you'll see that by doing that, then we can get these awesome topic bounce. Okay, so do you have any of the time, the algorithm takes on the input of size and so sometimes I like to just write it like this to you then like that this takes big of and I started to go have one. This recursive call well it's it's on the input of size and minus one, so this takes tf N minus one, and this recursive call also takes to you then minus one. So. When I say this is constant time let's just call this some constant see let's say that this takes see time, maybe see is like a second maybe see is like a fraction of a second whatever it is it's constant it. I know that it could fluctuate a little bit, but it's not going to grow with the size of the input and that's the important part. Okay, so let's see. here's our occurrence. Why is it Okay, so it looks like I have two recursive calls Why am I only. Doing one. One term of tf N minus one in the recurrence. right because, like you said they they don't they don't ever both execute right it's either one or the other, and in both cases it's tf N minus one, so you just get this. Okay base cases are also. You know there's also constant time. And so we have a nice recurrence it's in terms of constants but that's Okay, we still can kind of use our techniques. hey so let's let's solve this is our recurrence relation. let's solve it by unraveling. history of tf n is equal to tf N minus one plus C. Okay, so, then the next step is going to be t of and is equal to. An inside of here. I put t of N minus two plus see. I have a policy. All right, let's clean that up. Okay, three I get tf n is equal to. Now let's break up to you, then minus two and I get t of N minus three plus C. Plus C plus C. And in general. You get to event is equal to t of N minus K plus K see. right sort of get down to the base case and is equal to one, I want to plug in and minus one and I get to van is equal to t of one plus. And minus one see. Which is equal to some constant D plus and minus one C and. What is C and D, we really don't care, all we really care about is how this thing grows ask them topically, so this is going to be. The event is big data event shouldn't really be super surprising, but this at least gives you a way to to see how the how that recursion is. Working okay any questions. Okay. let's talk about another problem merging two sorted lists. So you have a one through eight K and b one through bl. And let's say that N, is the sum of the two lengths, and you want to produce a sorted list that contains all the elements and if some of you may have seen this before, this is a sub routine of merge sort, which is a. Common sorting algorithm that we're going to look at it in a minute, but in order to look at merge sort, we need to first figure out how to merge. Okay design a recursive algorithm to solve this problem does anybody have any ideas. so good, we need to have the base cases that's very important. Okay, good, so this is the type of. This is the type of thinking that I want you all to start trying to do with recursive algorithms is. make a decision that will shorten the input. And then recursive Lee solve the problem on that smaller input, so that way kind of. You kind of have to like let go a little bit and have faith that the algorithm will work. I call it faith, but in mathematics, we call it induction but sometimes it just feels like you just need to believe right. Okay, so good. So. focus on merging the head elements right the first two elements, because of the two lists are sorted than the smallest element has got to be either the smallest element of the first list or the smallest element of the second list. So, once you figure out what's the smallest element, you could just merge the remaining lists. Okay, so good so here are the base cases again base cases. And then we have. The if statement right if a one is less than or equal to a B one then. This is called are merged for recursive merge. Our merge. The remaining elements and the list a two through Ak be one through bl. And if it's the other way, then be one is smaller and so concatenate be one academy one, with the result of merging the full a list and b list, starting from P to. Any questions. Okay let's prove it we're going to prove it by induction, and this is going to be induction on end, which is the total size of both list put together. Okay, so base case suppose and zero, then that means that both lists have to be empty and. That sort of taken care of in these two first lines. Okay, so it trivially sorts it okay that's fine okay induction steps suppose and is greater than or equal to one and our merge a one through a kb want to be l returns a sorted list containing all elements from either list whenever the some of the Atlas length is. N minus one, what do we want to show now. That for any. list. Of length and our merge. correctly. merges the input. Here we're also using regular induction again, and the reason is because, just like before if our original list is of length n both of the recursive calls are of length N minus one. Right, because each one of them you're just only taking one thing away. Okay, so here's my induction hypothesis this thing. Right, we want to prove that for any other list a one through ap be want to be Q returns is sorted list containing all elements from either list whenever people ask you is equal to, and for any. For any list that of size n so case one at least one of the list is empty then return. Other list. Which is sorted. And contains all elements. Okay, so that's kind of like the easy part caves to neither of the lists are empty so that means we kind of have to go into. This part of the algorithm let's see what happens. Okay, so this is what I just said least one of the list is empty similar to the base case and in the first or second line return the elements return all the elements and sort of okay that's good. Okay, so we're going to split up case to into two sub cases right, so we have to a is going to be. This recursive call. Since both lists are sorted this means and and a one is less than or equal to be one, this means a one is the smallest element overall. The total size of this input here. is always taken away and element from a so it's P minus one plus Q, which is N minus one right, because this is assuming. P, plus Q is equal to end. So by the induction hypothesis that recursive call. correctly starts the list for free right you don't even have to do anything you just kind of use the induction hypothesis, and you get a sorted list. So, what happens if you have a sorted list, and you put a very small element in the beginning of the list, the result is also sorted. And a one to the start maintains the order and gives us sorted list with all elements okay questions about that. Okay case to be very similar since both lists are sorted this means be one is the smallest overall, if I have be one is less than anyone when it's the same thing right you you pluck a. You you pluck it element from the B list. And now you get P, plus Q minus one and that's equal to N minus one this is assuming people as queue is equal to end. So it returns, a sort of list containing all the elements and adding be one to the start maintains the order and gives us sort of lists were all the office that's it. Conclusion we've shown that for any input size and greater than or equal to zero are merge correctly merges those two lists. Okay, any questions or comments. It negative one again. Can you be a bit more specific. Where does it say N minus one. Does so like Professor in the previous slides like you mentioned that P, plus Q is equal to N minus one is that does that mean, like the the queue is one position smaller than qq is like one positional MP. know people as queue is equal to n. Is that was a here. Yes, deduction status. yeah I got that but what, why is it minus one, though. Because P minus one plus Q. If you just do some algebra on this. So we're saying, like the the list of as like have one less element than the biggest. So we're okay so. let's go back so we're assuming that the a list starts with P elements and the B list starts with Q elements and we're assuming that the total number of elements is and. Yes, I got a. Few is equal to end right now here. I am. rehearsing on a list that starts at a to. So how many elements are in there, p minus one. And the entire list of be how many elements are there Q what's P minus one plus Q. Oh, I got it Thank you. one. And that's just an yeah. Okay, so how long does this thing take well if you do. A similar. Analysis you'll see that it has almost the same runtime recurrence as. The counting 00 thing that we just did right these first two lines are constant time. And then you only do one of the recursive calls and the recursive call is of length N minus one, so you get this same recurrence relation. Okay So how do we solve this, this is the same so it's going to be T event is equal to big oven, and you can. You can do this as an exercise, if you like, but really it's identical to what we just did. Okay, any questions about merging two lists because we're gonna we're going to use it in the next algorithm. Okay merge sort so, how does this work it's a divide and conquer algorithm. You divide the list into two sub lists you recursive Lee sort each sub list. And then you the conquer part is to merge those two sorted sub list, now the reason that we're allowed to use merge here is because the two lists are are sorted remember that's what the input for emerges, how do we know that those lists are sorted or how do we sort those lists themselves. Thank you, you split you have some jumbled list you split it up into two sub lists, you need to sort those sub lists in order to merge them together so here's kind of the thing is that, in order to sort them you sort them using the same algorithm. Right it's supposed to sort so it's got a sort the smaller lists. Okay, so here's emerged sort. You have some input of length end. Here are the base cases. Now let let em be roughly the middle. And we're going to split the list up from a one through a m N, a n plus one, through a n. And we are going to. recursive Lee call merge sort. Now, if you were designing this algorithm How would you know beforehand that merge sort would successfully merge or excuse me successfully sort those sub lists. How. You know. Okay, so. Okay, so you all are. You know, thinking about the recursive structure of the algorithm and it is important to know how that works. You know how you start out with a list, and you keep on breaking it up and all the way down to the base cases and then it kind of like builds it its way back up, but what I want to, I want to train you all to do is to start thinking only one level deep and so. This is especially important when you're designing recursive algorithms because, at least for me, I get I get lost if I try to go all the way down to the bottom, and then I under don't understand you know it's hard for me to keep track with everything so. The answer that I was looking for. It doesn't matter if this is the way that you think about it, you know if you want to think about all the way down to the base cases that's that's up to you, but i'm going to present a alternate way of thinking about it. Okay, if you were designing this algorithm How would you know that Murray sorts successfully sorts those sub lists. Faith just have faith in it. have faith that it does its job and then show that it will do its job sounds circular I know but that's the that's kind of the that's kind of like inductive Lee thinking right and so. This is going to be how we prove that the algorithm is correct, so I know I know this is not really a algorithm design class, but you know, maybe you will take an algorithm design class or you will find. find that you need to design a recursive algorithm and I want you to think back to faith think back to well. If I can, if I can assume that it works on small inputs, how can I use that to my advantage to have it work on bigger inputs. Okay, so. Now the picture we all want to see right merged sore How does it work, this is really kind of what's going on. You start with a list you break it into two each one of those is broken into two each one of those is broken into two until you get all one element subsets each one of those I think some I think this is what somebody said in the chat right each one of those is single element. That is trivially sorted. And so, then you start merging those things into pairs right and merge them back now. What i'm proposing that you the way you should think about this, is to only think one level deep. And so, that means that we're going to hide all of this stuff. All of this stuff is taken care of in the recursive call so really the only thing that we're doing. let's let's hide it with red right. hidden. So the thing only thing that we're really doing is. we're splitting it up right that part that's the first part of the algorithm we get these sub lists. And we immediately jump to here. And here. And then we say oh by faith. We get to sorted list. Now merge our merge we've shown that that is already already work so, then this last part is. By the correctness. Okay, any questions or comments or philosophical arguments or theological. i'm interpretations of faith and God and math and induction. And, just to be clear. Whenever I say faith, I really just mean induction. So replace each word of faith by induction I don't want to be called out as like you're trying to force my religious beliefs on everybody. Okay, so let's do the. let's let's do the induction let's let's put the faith into action right. Okay, so we're gonna we're going to prove this algorithm using strong induction what is the reason that we're using strong induction. let's share. Okay, most people are saying see. Because we're calling the function recursive Lee twice so that's not. that's not the reason. The reason is the input size. Of the recursive function call is less than N minus one, because what is the input size of the recursive call. If this is length n right. Each one of these is an over to. Okay, so should we go Julie, to talk about this, do you all have any clarifying questions about when to use strong induction and rent to you when to use regular induction. it's not clear. it's not clear to you why we use it in this case or it's not clear to you the difference. You want me to explain in general, or just for this particular example. In general okay so regular induction I like to think of induction is a ladder. And it's just me. A ladder to heaven. Based on faith no i'm just playing Okay, so you have your base case. Regular induction. You use the N minus one sub problem. To prove the end sub problem. or, in other words, in order to show the end sub problem you use the information from N minus one. So. it's really a kind of a very nearsighted. idea you, you only look back one step right maybe you're afraid of heights and you don't want to look down you don't want to know what you've done all you care about is that you're on that step and I can get to the next step that's it. Now, in strong induction. You have your base case. it's like getting on to that first step, or so. And you're still trying to prove an but instead of only knowing that you've been on that step. You use the information of. All the steps that you've taken before. Now, why is it useful to do this with this particular algorithm merged sort is because and over to his right here, right. So an over to falls in that range and so. You could argue that strong induction is kind of overkill for this problem, because we are, we are assuming way more than we need to. it's just that we're assuming this big thing this big range of values, but really We only need one of them, but that one falls in the range, so it works and so that is why we're using strong induction here okay questions or comments or is still is still unclear. Right, because you know you have an over to here also but, like you said, like maybe you're you're climbing up. Think about it like this, regular induction you're climbing a ladder in the dark, so you don't all you know is that you've. You going from the step that you're on to the step that you're going to and strong induction is you're climbing a ladder, in the light of day, so you have you can look down and see oh i've done all that oh i've done in over to, I guess, I can use that information to get to the next step. Okay. So let's do the induction base case, if any zero then returned the empty list is trivially sorted if and is one return just the singleton list is truly sorted okay so bass cases done. Okay induction step assume. That merge sort correctly sorts all this with K elements for any K in between zero and N minus one, so this is the you know, this is the. wasn't strong induction was in purple. So here's here's the link the. the nth step. here's the zero step. And minus one, so this range here is talking about all of these steps here basically we're assuming that merge sort works on all of these steps. And now we want to show that moves toward works at that next step and. Okay. So i'm just going to Oh, I guess, I need to fill in the blanks okay it's fine all right. How do I prove this okay so. we're assuming that n is greater than one. We split. The list. into a one through eight. And a n plus one, through a n. Right. Then by the induction hypothesis. Since. A one through am since the number of elements in this list is strictly less than n. merge sort. or l one is equal to merge sort of a one through eight. is sorted. Then by induction hypothesis since. The number of elements from a n plus one, up to a n is strictly less than an L two is equal to merge sort. A n plus one, up to a n is sorted. Then by correctness. of our merge. Our merge. l one L two. Is a sorted. list. Of all. elements. Okay questions or comments about the correctness proof. You how how much we're we're relying on induction how much we're leaning on it, we need it bad, it is the driving force it's almost kind of like the the. Where where you. were using it to its full advantage here, it seems. Oh, are merged just means recursive merge because there's a iterative version of it but. it's just the algorithms that we did here. Are merge that's what I called it. We always going to be assuming the algorithm is correct. When you say always are you talking about every algorithm that we encounter. What do you mean by that. yeah So if you want to prove an algorithm is correct recursive algorithm is correct, you always assume that it's correct on smaller inputs. And if the algorithm war, I mean if the correctness prove works right if you're able to use to leverage that into a into the algorithm being correct then your algorithms great it's correct, but what might happen is that. you're even if you assume the algorithm is correct, on smaller instances. That might not be enough to show that the algorithm is correct and so. It all depends on the proof, but yes that's always going to be the inductive hypothesis for for proving recursive algorithms are correct. Okay, so let's talk about the runtime here. This whole thing is going to be constant time let's call it what did I call this C one C zero. And then each one of these recursive calls is t of N minus two in over two if this is to then do you have an over to T event over to, and this is the time it takes to merge. Of the input of size and remember that we've you know recall that we. We calculated this. Right. So here is our recurrence relation, but we can we can replace merge with big of an and we get this Nice. recurrence relation here. Okay, so let's try to solve this thing using unraveling. Actually I should I should. I should rewrite it instead of big old endless right in terms of. let's call it C and. Okay, so let's do the unraveling. So the first step is going to be to human. Is the original records. Okay, the second step. Two, and then we will what is how do we. How do we do this one it's going to be to T have an over two divided by two so that's an over two squared plus C and over two. All right, let's clean that up that's going to be two squared T have an over two squared. plus two times CN over to his CN C n plus. Okay, how about the next one. We have two squared. myself a little bit more room here. Okay, this is going to be two T have an over two squared divided by two is an over to cubed. Plus C times and over two squared. still not enough room. So let's clean that up we get to cubed T have an over to cubed plus two squared time see and over two squared is just CN so we get see in policy in us. You might start seeing a pattern right the case iteration is going to be t of and as equal to two to the K T have an over to to the K plus Casey and. Right. In general, now we need to, we need to plug in a number for K that will bring the. The recursive call down to one right or right that whatever is inside of the team, we need to bring that down to one, so how big do we need to make K, in order to get down to the base case. Around log base to event right exactly because you're really just asking how many times do I need to divide by two to reduce and down to roughly one, so if I put in log base to have in. Then I get to heaven is equal to to to the log base to event. Times T have an over to to the lock based to have n. Plus log base to have n time see times in. Right. And this is just and T of one plus C and log base to event and tier one is just some constant to, so this is just see one and plus C and log base to read. Okay, so. This is the this is kind of the result of. unraveling and you know I don't know if you're bothered by this but I put in log base to event, but it could be the case that K is or that and is not a power of to sort might not actually divide out evenly but remember we're doing these kind of. asset classes, so the the fine details kind of get swept under the rug so in general, this is this is good enough for us so based on that. We can say that. tf n is see one and class C and log base to end. And so to have an is big theta have an login. Which. is why his team are big on. here. Okay, so let's think about the general strategy of divide and conquer merge sort isn't the only algorithm that uses this strategy, and we can generalize it. merge sorts what's the problem in to each problem is of half the size. And it does some work to combine them taking linear time, so if we kind of change these things up, in general, you divide the problem of and into a sub problems each of size and over B and then you conquer the size, the size, by combining the solutions of the sub problems. So. If I go back to this poll. I divide the problem into a sub problems up see. A sub problems each of size and over be and we assume that G event is the time to do the kind of conquer step, or in other words the. Non recursive part. Then. What is a recurrence for tf n. Share results okay so most people are saying a. So you split the problem into a sub problems right, so you have to do a recursive you have to do a different recursive calls. Right, each one of those calls takes to have an over be time so somewhere in your recursion you should have the a times T event over be and then, when you're done with the recursion the non recursive part just takes Jia, then time, so this should take. Questions or comments about. So if you have a recursion in this form, and G event is a polynomial. Then there's a nice theorem called the master theorem that. That you can use. Without proof in this class I guess. And you'll learn a little bit more about it in one on one and essentially it's just more of like a shorthand way or like a shortcut way to get to the answer so that you don't have to do that unraveling for every single thing. Okay, and here it is in all of its glory the master theorem. Okay there's three parts and this kind of depends on. How the what the recursion tree is doing okay so. um. let's start out with the recursion so we have to event is equal to a times so this a year is the number. Of recursive calls. This be here is the. or this and over be I guess is the size of each sub problem. And this big event of the D is the. time it takes. For the non recursive part. Okay, so let's go through each one of these is a is is less than B to the D, then what that means is that you're not splitting it up a lot right. And I guess that be right is really big, meaning that you have. The size of the problem has reduced a lot right so at each layer of the recursion tree, the size of the problem has reduced a lot, and you haven't really split it up into that many problems, so the amount of work that you're doing. decreases as you go down the tree, so this thing is called top heavy. And it means that. Most. work. is done. In the top. layer of the recursion tree. Okay now. This one here is it a is equal to be in be to the D, that means that the amount of work of each layer is roughly equivalent so you're doing a roughly the same amount of work in each recursive in each layer of the recursion tree. And so that's why there's a log in there it's because you're basically multiplying the time it takes to do the top layer by the number of layers if you're assuming that they all are cons are are equal time, this is the, this is the kind of format for merge sort, as we saw. What I guess we didn't really see it, but we figured it out with the unraveling. Is that you're doing the same amount of work in each recursive step that's essentially what these. What these see ends were we're telling you those are basically telling you what the each one of those recursive steps are and so you're saying i'm doing this, all the way down. So this is called steady state. And this is. Equal. time for. later. Okay, and then the last one is called bottom heavy. And that's going to be when you when you kind of when the when the tree kind of spreads out faster than it's decreasing right or that the size of the sub problem is decreasing, so you have a lot of branches right as big and be as small so you're you're not. you're not decreasing it as much right and so all of the work now is going to be on the bottom layer or most of the work. Okay, you don't really have to memorize all this stuff you can just write it down and use it as a reference all you have to do is. Come compare A, B and D. figure out what their relationship is and just write down the the the case. The one we did know the one we did is steady state merged sort of steady state, I think I have it here. Right merge sort a is equal to to be as equal to two and D is equal to one, so a is equal to be to the D to is equal to to to the one, and so we use the middle thing right because a is equal to be to the G big of an okay. here's kind of a picture. i'm. Right, the the tree is going to branch out into a sub problems I guess in the picture is equal to four But just think about a in general. And each one of these sub problems is of size and over B and you kind of bring it down all the way down to the bottom level and the bottom level is going to. Have. A raised the log base be of and sub problems and that's because. One is equal to an over been to the log base be have an right the depth of the tree is log base, be a man. And so, if it's top heavy most of the stuff is at the top of the tree bottom heavy most of the stuff is at the bottom and steady state means that you're doing the same amount of work for every level. I meant to say I get what he represents, but what about be to the D so. Be is this or an over be is the size of each so problem. And, and to the D is the time for the non recursive part of the algorithm. So maybe i'll do one more example. But what about be to the D. I don't know if I understand, do you understand what be is be is like the. Like in this case let's do it like this. Be is this number that's inside right it's an over be whatever number that's there that's B and then D is the exponent of n. D is so. So emerged sort this was the recurrence relation now this follows the form of the master theorem because you have this this guy is a is equal to to be as equal to two and this part here is a is a power of n it's into the one power right. And so D is equal to one. So you know if. If there are three recursive calls. Each of size. and over two. And the non recursive part. takes. Big of n squared time. Then. The runtime. Has the. recurrence relation. To have an is equal to three T have an over to right number of her personal calls and then plus big of n squared. Right now, we can break this down this three is a This too is be in this too is D and so now we compare. Three is less than. Two to the to write a is less than B to the D. Therefore, that means that if I go back you can see that that means that i'm in the top heavy version. And so that implies that tf n is equal to a bigger and to the D in this case big of n squared. That clear it up. yeah okay good okay so i'll stick around for a few more minutes to answer any follow up questions. It means you do most of the work of the top of the recursion tree it's kind of hard to talk about start and finish of a recursive algorithm, what do you, what do you consider to be which right because. You can kind of think about it, as I can merge sword you're just breaking it up first and then you're putting it back together. So. top heavy means that most of the work is in that last recursive call the the the last one that gives you the final answer that's where most of the work is done. Bottom heavy means that most of the work is done after you've kind of broken everything down to their individual bits and you're working on those bits and you have to do a lot of work down there. And then it kind of builds back up to the top that's bottom heavy steady state means that the amount of work you do is steady throughout the entire recursion tree you do the same amount of work, each time. So originally I said see and then I was thinking a and then he said it was see and what was confusing me is why we don't have a times you Ben and we just have Cuban. But each recursive algorithm has two parts, has the recursive calls and then it has the the rest, the rest of the stuff that right. So you do all those recursive calls. that's clear that's going to take a time to event over be time to do the recursive calls. Right yeah that part mason's. The rest of the algorithm i'm claiming that it takes G event time so. Whatever, that is to come up to split the list to check to see if it's a base case, like all of that stuff is all kind of pushed into that g of enter. Okay, so it's not multiplied by the sun problems because the entire thing itself is just human. Just like emerged sort. right that G event is kind of like the merge part or that's the part that takes up the most time. it's separate from the recursive calls that's why you added. Okay, thanks y'all see you all next week have a nice weekend.