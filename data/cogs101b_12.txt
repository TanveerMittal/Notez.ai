 Hey everyone. Welcome back. It's two o'clock. We'll give it one more minute for last minute people to Rollin. But in the meantime, Are there any logistical questions? I can answer? Oh, actually, I have a question. When so so I guess this is Seward question. I took the quiz yesterday, the new quiz that came out, and I kind of assumed they were for not, not to spoil anything for anyone who has taken it. So I'm not going to say anything about specific questions, but like I assumed they were first content last week, but there's content from this week on there and content that we like hadn't even covered yet. Reason. So is there a point at which we're supposed to like me to do that? Are we able to take it at any point throughout the week or should we wait longer? It should. There could be that could be a mistake on my end. It should not cover material from this week. Okay? So that is a mistake to go back through after class today and look at it. But thank you for pointing that out. Yeah. I think there was stuff from Monday on there. From Monday on there. Ok. I'm I think that that is an error. So I'll, I'll think about what to do about that. For those of you who have not taken it yet, hold off on taking it. I'll send an announcement once I look at the quiz and kind of figure out what to do, I don't think it's a huge deal, but I figured I should munch. Yeah, but yeah, it ought to take a quiz that you haven't been exposed to the material yet. Ok, hey, I think probably what happened is because the last couple days have gone slower than anticipated. I had like slides prepared to cover last week that, that I didn't get to into us thinking there from last week, but it's actually wasn't covered by Monday. I see Henry saying, yeah, it was from slides her last week, but we didn't actually get to eight. Yeah. That seems like what happened. So maybe what I'll do for that is I'll just push the deadline out a few days to kind of give us some breathing room on the material. But I'll look at the quiz and make an announcement when I decide what to do. Thanks for bringing that up. Any other errors or anything else logistical to bring up week five pad that will be posted today. Okay, let's get started. So not even further behind the quizzes. Start testing your material. It is two weeks away. So we're going to keep talking about attention today. We're still in this sort of first module talking about attention, this idea that we, we sort of framed attention as this kind of cluster of things. That's somewhat, maybe we know it when we see it, but it's difficult to define. And so we are going to talk about it, or we're talking about it with this overarching question about what is it for, what does it do for us? And so we've been talking about how it helps select relevant perceptual information to the exclusion of other information. And so this is this idea of selective attention, directing awareness to relevant stimuli. We've talked about how it's surprisingly attend to change minus inattentional blindness, attentional blink. And I mentioned these briefly last time, a couple real-world examples of inattentional blindness. But I wanted to talk about them in a little bit more detail because I think it's interesting and I think it's interesting to see how these phenomena can kind of affect real life situations. So I have this text on the slide for to have a record of this on the slide. But sort of tell you what happens. So in 1995, this police officer, Kenny, commonly a Boston police officer, he was called to a scene early in the morning. It was before it was laid out. And he was chasing a suspect and he ran by two other officers that were brutally beating a third person. The third person that they were beating was a plain clothes officer who had been called to the scene. And he had also been called to this theme to help. But he was mistaken because he was, they caught him climbing a fence hill, climbing a fence to go chase someone, but he was climbing offensive by the other two police officers thought he was a suspect and they start brutally beating him. This guy had all sorts of really about damage, kidney failure, and things like that. So it was really serious. And the whole department was sued and all of these officers were suspended. And the sort of tricky, tricky situation was this kenny commonly person who had just ran by the fight and when he was on trial, he his claim his defense was simply that he just did not see that happening. And the jury did not believe that they were like, yeah, it was dark, but there was flood lights. Very bright streetlights. Your yard way from this brutal fight happening, how could you have missed it? But he claimed he just didn't and he ended up being convicted of police misconduct and perjury and obstruction. Obstruction of justice doesn't all these things. So this motivated the study. This was done by some of the same people that did the inattentional blindness study, the original gorilla study. And so what they did was sort of asked, you know, is this possible how many people in a similar situation would miss this? And so they staged a fight on the street or on campus, I guess. And they had subjects run after the experimenter. Should be really funny. Sony experiment, you show up to soda and you're asked to go jogging with the experimenter. And so years was to follow the experimenter and count how many times he touches his head. There's three conditions. There's the low load condition which are just jogging after the person. There's the high load condition which you're counting how many times the person touches their head with just their right hand. And then the medium load condition, how many times they touch their head with either hand? There's a fight that's visible for 15 seconds, eight meters away, so that it's in their visual field, her 15 volt like pins. And what they find is that in the high load condition, more than half of the people actually miss the fight. So 42% of the people who are counting how many times the experimenter was touching their head with their right hand only miss it. And even in the low load condition where they're not doing any other tasks, 72% of people miss the fight. So of course this doesn't answer the question of, you know, Kenny calmly and whether or not he was in on the cover up or if he had actually not seen or if he'd actually not seen the fight, but it demonstrates that his story at least is plausible. And another kind of interesting studies that have looked at inattentional blindness. So this, these researchers were interested in the interaction between inattentional blindness and cellphone and electronic use. And so this is, this aerial shot is, Pat's students would take through this quad on this college campus. And what they did is they set up this clown on a unicorn riding around the campus quad. And then they just, they didn't manipulate anything for individual subjects. They just have them walk. They just waited for people who were walking through in them and they got to the other side. They ask them if they had noticed anything or did you see a clown? And they found that in the bottom row here, did you see the clown? Unicycle? What did I say? I say unicorn. Scarcely. That's amazing. I read, I was I was shopping on Amazon earlier and there was a coffee mug that was advertised to me. That was, always be yourself unless you can be a unicorn. Unicorn. And so maybe I was primed. That's amazing. So refer 80 and unicorn slip. If you're on the phone, only 25% of people report seeing the unicorn. And even people walking by themselves, only 50% of people see it. And if you're walking in a pair, you're the most likely to see it. Okay. So just some examples of how, you know, kind of going through our daily lives when there's any amount of distraction, there's encounter inattentional blindness. I meant to say Unicorn the second time, just for the record. I'm sorry, that's a really funny critics and you'd agree. Okay, so one of the questions that we left off talking about was this idea of like how we know that it's limited. How do we go about selecting the information? When do we start to tilt for information out? And just to kind of review what were left off talking about last time we talked about these early selection models and he's late selection models. The basic idea is in his early instantiations of Attentional Models. Researchers were using this kind of flow diagram, talking about how the information comes in. There's a sensory analysis stage, then analyzed for full meaning, and then it enters working memory. You're conscious awareness. And there's just an idea or some sort of bottleneck, some sort of limit in perception or, or processing. Some researchers have talked about it being an early selection where the filter happens before meeting processing occurs. Sort of selecting on sort of physical or perceptual features. And the late selection models basically just move the filter and they say that there is a filter, but full meaning analysis happen. It just doesn't get fully processed or make it to working memory, you're conscious awareness. And some of the reason that this filter a sort of moved with some research that we left off talking about where you can essentially have priming in one ear. So are priming the non attended channel. So you're, you're doing a dichotic listening task. You're attending to the right ear, say. And there's speech about, there's a sentence like they threw stones at the bank. Bank is an ambiguous word. Is it a river bank or financial institution? Now, in the unattended channel, there's two conditions there. Either saying river water cues for a riverbank or they're saying money dollar cues to Crimea and financial institution interpretation. And it turns out that how you interpret the word bank depends on information in the unattended channel that you weren't aware of. And so this is reason to move this filter later suggesting that full meaning analysis is happening. It's just not making it to conscious awareness, but it is influencing or meaning or interpretation of meeting. Okay, so that's the sort of distinction between early and late selection models. These really popular for a really long time. Which one is right? Probably. There's, I think a little bit more evidence to suggest that these sort of late selection models. Seem more or consistent today with the, all the experimental results. That said sort of newer roles that aren't necessarily using these filters are flow diagrams can actually explain the same empirical results. And so this is kinda what I was talking about last time about how even when you have a model that kinda can kind of explain things. It doesn't necessarily mean this is what the brain is doing. It's one plausible suggestion about what the brain is doing, right? So a more recent model, something that's taken more seriously today's this theory of perceptual load, Perceptual Load Theory. So essentially according what a Perceptual Load theory says is that attention is a bucket and our bucket is always fall. It's a limited capacity. That's what I mean by it being a bucket. We have a certain side bucket. And we're going to fill that bucket. First. We'll fill it with task irrelevant stimuli. Those are the things we'll first put in our bucket. But anything else that's going on is going to fill the remainder of that bucket. And so all these attentional resources are used up, the bucket is full. So some relevant terms are this idea of processing capacity. So that's the amount of information that you're able to process at any given time. And our processing capacity is limited. There is a fixed size to our bucket. And this resource, this bucket is flexible. We can allocate it to process different things. So if you have just sort of visualization of this idea, if you have a low load task, an easy tasks, something that doesn't fill your bucket. It some less than a 100% of your resources are going to be taken up. And then you're going to have some remaining attention capacity. A high-low task or a really difficult task is going to fill the bucket, is going to leave you with no processing capacity leftover. This is a tensional load theory of attention. And the interesting thing, one of the interesting things about Perceptual Load Theory is that it makes some, I think, counter-intuitive predictions. Yes. Can you reduce the perceptual load of a difficult task as you become more proficient in that house? Yeah, absolutely. So some last quarter I think somebody asked, can you change the size of your bucket? And you can't necessarily change the size of your bucket, but you can effectively change the size your bucket by getting better at some certain task. And that reduces the Amount of liquid and say in your bucket right? Leaving more roof leftover, right? And so this is sort of well, sir, what do you mean by flexible allocation? Stowe? Good question. So let's go back to this. This would be less of a flexible allocation where it's talking about these bottlenecks as selecting on certain features. Is it physical features? Is it processed for meaning? Is it not processed for meaning? Sort of talking about attention as if there's some sort of preprogram about what's going to be selected by flexible allocation of resources. It means that depending on the tasks that you're doing, what goes into your bucket can change if that makes sense. So there's x, there's x number of, there's a 100 units of things. You could pay attention to your bucket hold 70. You can choose 70 out of those 100 to put in your bucket. So that makes sense. Yeah. Thank you very much. Yeah, sure. So in this study, they just do different condition than what you have to do is you're just presented with this array, the circle of letters. And in the easy condition, there's ends nose and you just have to say, is there an end present? In the other condition, there's much more possibilities of stimuli. So there's say like all of the 26 letters represent and you have to say if and n is pregnant. And so in one condition, the n is going to be sort of the odd man out. In the other situation, it can be perceptually more difficult to identify the letter n. So what they find is if you look at reaction time, people in the NO condition are gonna be faster to recognize the n compared to in the hard condition. In the secondary task, they have people do this same task. Only now they present a cartoon character. Ok? So this is where I think the results are a little bit interesting. So which condition would you guess will be more affected by the destructor? Most intuitive. Nathan saying hard, that would be my guess, right? So I'm getting people saying easier task. So the, I think the intuition for me is that you're doing a hard task. It's really, it's easier to get distracted from a hard pass in an easy task. And maybe other people have the opposite intuition or maybe you've internalized perceptual load there. And so you're making the prediction that Perceptual Load theory would predict. Which is that it's actually going to the easier task, the reaction time per proportionally is going to take a bigger hit than reaction time for the hard task. So proportional to the initial reaction time. The easy to ask in the easy it has condition you're actually slowed down more by this cartoon character. Then in the hard task, does anybody want to attempt to explain what, how, and why Perceptual Load theory would predict this. That's a tough question. So the idea is in the ease decondition, you, your book, it's not very full. And so all this attention left over to pay attention to the cartoon character to fill your bucket with that distracting IAM. Compared to in the hard task where your attention is full or nearly full. So your attentional capacity or bucket as folder nearly full. And so there's not as much room for that, that cartoon character to fit in your bucket and take up attentional resources so you just don't have any leftover. And so kinda counterintuitive prediction and which is nice for Perceptual Load Theory because it does sort of make these counter, at least to me, counterintuitive predictions or predictions that could either, could go either way, right? And the idea is that an easy task, these resources leftover available to process this task, irrelevant stimuli, it gets processed and slows you down. In the harder task you have a little resorts, says remaining to process the other stimuli. So the irrelevant stimuli, they can't be processed or its process very minimally and has less impact on your performance in the task. Kay? So this is kind of a fun little demo of. So watch this video and I'm going to ask you a question based, based on their perceptual Dairy. How much or how little we actually aware of. We decided to recreate one of Simon's most famous experiments to see for ourselves. Here's the setup. Our senior series producer Vin poses as a loss pedestrian and asks a passer-by forward directions. Excuse me. I'm looking for the skyline. Then we break the two up, walking through them holding a large sheet of wood. Now watch as I replace vein. You might think people would notice the switch, but almost half the time they did. Of course, that means more than half the time they did. We only try the experiment nine times and by no means was it good science. But we were surprised for people didn't notice the switch. In Simon's original experiment, seven out of 15 people didn't either. So what determines whether or not you can figure out the switch? Yeah. I don't know why the first guy got something then. You see, it did seem a little bit like a overreaction rate. How much? Ok, so little replication of a famous study by the same guy who did the gorilla study. Okay, so. Try this question. My question to the last task. For the harder processual task was the response time it didn't change, right? Thorn, cartoon. It did slow them down. Yeah, it did slow them down just not as much. Ok. So the the the inference there is that it wasnt filling their bucket completely. There are still a little bit of attentional resources leftover to be distracted a little bit, just not as much as in the easy task. Okay. Thank you. I'll right click and if you haven't yeah. Crates. Most people saying E. Perfect. Yeah, so the idea here is e, both a and d. So for somebody that is familiar with the area, they'll have a lower perceptual load in trying to give somebody directions. And therefore, they will have less load in their bucket. There bucket will be blessed bulb, and so they'll have less. In the study we looked at with a cartoon character that perceptual, that remaining empty bucket could be used to process the cartoon character and reduce reaction time. In this situation, there's that extra attentional capacity left over to notice things that somebody with a higher perceptual load wouldn't notice. Hey, alright, so that concludes our discussion of selecting relevant processual features as a function of attention. And so now we're going to talk about some findings that have shown that attention can actually enhance certain perceptual features. We're going to. Okay, so we've talked about how spatial attention can be compared to the spotlight beam. And we can shine it anywhere individual field attending to some things at the exclusion of other things. And so, so one question is, how do we decide where to shine the spotlight? What types of cues in the environment are going to guide or direct our attention. So try this task. Find the vertical red bar. Hopefully, you've all found it now. So this is a pretty easy task. It's known as a pop-out effect or visual capture. And it's when a unique target pops out, it's has a feature that's different from the rest of the distracter, distractors. It captures attention in sort of a bottom up fashion. And yes, are people who are color blind? I haven't I didn't think about that. Would pretty nice lives together. And so assuming you're not colorblind, this will pop out at you in this bottom-up fashion. And the way that people seem to be processing stimuli like this is in this what's called a parallel search. So it's not a parallel as trusted with serial. So serial search would be that you have to look at each individual item. Judge, is it read, is it green? Move on to the next item, shining a spotlight on each subsequent object. That doesn't seem to happen here. It seems like we analyze all of these items in parallel. And this one jumps out at us. And has to do with the fact that this, there's just one single perceptual dimension that we can respond to in this bottom-up way. Similar to something like this to find the furry thing. So in that sort of situation, again, you're searching the scene for one perceptual feature. It's not the strongest pop-out effect like in that earlier visual search task. But you are searching the scene for one-dimensional or one perceptual dimension. So it makes the search pretty easy. Now try this one. Find the vertical red bar and missing. Raise your hand and you found it. It's difficult, right? So something that I've noticed when I do this in class, and a happy will raise their hands is like 25% of the people raise their hand right away. And it's only because they happen to be looking at the quadrant of the screen where they're vertical red bar was ends up kind of like right in the middle. But it's much more difficult. We've just added this one, extra perceptual dimensions, and you can no longer do this sort of parallel bottom-up fashion search. You have to do the serial search where you're looking at each individual object and your scrutinizing it for, you know, is it, is it read, is it vertical? Too many bottom-up cues to be useful to have to do the serial search. We have to shine the beam of attention on each object. And the reason models that have proposed that visual search in these sorts of stimuli happens in serial is that as you increase the distractors, reaction time to find any object increases. Alright, so find the tester. So for somebody who found the toaster, can you articulate your strategy for finding the toaster? Did you have a game plan? So basically I think your toaster has on the desk. So I search for a depth-first. Yeah. Yeah. So you have this knowledge of scenes that knowledge of kitchens, kitchen toasters usually are on the countertop. You probably didn't scan the floor or the tops of the bar or something like that or the sink. You probably limited your search to this far-off countertop area. And a lot of people are saying things about the countertops. And so there's this explicit awareness. And perhaps in a class talking about attention, talking about visual search strategies. So maybe this is why you're where does, but even when people are not explicitly aware of doing this, we do something called, we're subject to something called contextual queuing. And contextual queuing is this idea that we scan visual scenes based on statistical regularities in the scene. And I'll show you several different examples of this. They could be sort of more abstract statistical regularities. Or they could be statistical regularities. How kitchens tend to be organized in the world. And so even when you're not aware of doing this, if you were to put people in AI scanner and show where their eyes scanned, most people will be scanning that back countertop area. When you have people look at photographs or paintings. And then you ask somebody like, when you were looking at this photograph, What did you look at? People will kind of self report that to the whole picture. They kind of scanned the whole thing. They won't necessarily have this insight. But what people tend to do when you actually look at eye tracking studies is that their, their gaze, there's a cod, tend to jump from faces too interesting or emotional interactions to things that people report being interested, interesting in the scene. So if you have a group of people and you ask them, you know, what, what are the most interesting features in this painting? And then you look at a different group of subjects, eye tracking data, those two things will match. So what one group of people who reports to be interesting, where does the cause land and another group of people, even though people aren't aware that they're scanning there, automatically scanning the scene in this fashion. And one concept related to contextual hearing. A lot of things in this class, we'll talk about this idea a lot when we talk about long-term memory. But something related to contextual queuing is this idea of a schema. And a schema is a very broad term for any cognitive framework or concept that helps organize or interpret information based on past experience. But in specifically in the domain of context and in perception and how we allocate attention. In scenes, a schema refers to our a model of a physical scene or a physical space. So we tend to know how kitchens are organized and where the toaster is going to be. We tend to know what type of objects or in offices and how the offices tend to be laid out. We can scan quickly to where the computer is in the scene without being familiar with this particular room, right? And schemas likely help us form what are called saliency maps. So saliency Map is going back about toaster example. Areas of the visual scene that are going to be relevant for the task at hand. So an early study that showed contextual context facilitates recognition is the study by Palmer 1975, classic context study that shows the cont, how important context is for recognizing objects. There's the scenes in the scene isn't really a space so much as it is a group of similar objects, right? You wouldn't be able to tell whether this was the kitchen without the objects in the kitchen. And so what they do is they present different scenes like this. And then they do a task. I'm going to press a button in a second. You're going to see an object flash really quickly in your neck to say what it is. And so what was it bred? Yeah. How about this one? Mailbox, great. And then they do a third condition with a drum. And so what they find is that the most accurate condition when it's when it's paired? So when you have the kitchen objects, you see the kitchen objects first and then you're shown the bread. People are very accurate identifying the bread, but they're very inaccurate identifying the mailbox. So it's perceptually we similar to the bread. And so the, the context of the kitchen actually blocks your identification of the mail box because you're, you're cued to think about objects like that, look like this that are in kitchens. And so it triggers bread, but it's actually a mailbox. Your slope or your less accurate people are less accurate to identify the mailbox and this condition. Compare to this control of a drawn which is not related to the perceptual stimuli outbred. Yeah, exactly. The mailbox looks like the bread. And so the context facilitates the bread, but it block something that's perceptually similar. Other findings similar to this. If you ask somebody to find the fire hydrant when it violates positional constraints in a scene that we are expecting a fire hydrant to be on the street, people are going to be slower to identify that. Header. And then you can also find contextual cueing in more abstract properties of scenes. So in this study, they asked what, what properties of scenes are we actually using as contextual cues? Is it just like familiar objects and scenes? What properties are relevant? And so in this study, what they did is they had people find the letter T. And there's all these L shapes and they have to find the t. And with participants didn't know, was that the scenes repeated. And so there are several scenes that we'll repeat it over and over again throughout the trial, even though they weren't consciously aware of this. And what they found was that even though they thought that the stimuli was randomly generated, as the scene increased, we've shown more and more so an epoch is how many times it appeared. So there's the first time it appeared, the second time, third time, fourth, fifth, sixth time. And then on the y axis, you have reaction time. And what they find is that even though people aren't where the steam is repeating, they think these stimuli are randomly generated. There's something about that see repeating that guides Visual Search and people get a lot faster at identifying where those objects are. And so the ideas that we implicitly learn spacial layouts, we're not doing anything conscious in the search tasks, but we're implicitly learning those layouts that we've seen before. And that's helping to guide our attention even beyond our conscious awareness. And in this second study, in the same paper, they were interested in. Could it be something about not the spatial locations in this study, the spatial location of these objects stayed the same across epochs. Now, what they're interested in here is it is not that the configuration of the objects, but just the objects themselves. So what they did is they basically co-varied the objects in the scene so they're randomly located. It'll be the same set of objects across different scenes. And so these are just randomly generated objects. They didn't want to use objects that had preexisting associations. So they randomly generated these different object shapes. And what they find is that in scenes where there was high co-variation of similar types of abstract objects, visual search, I'm improved and people were able to up to find the symmetric object faster in trials where there was high co-variation of similar objects from earlier trials. So basically kind of, you know, this would be, there's high covariation in these objects. In our experience in the world, right? We, over many, many, many instances we've seen cutting boards and knives and spoons and whatever co-vary. And so this is sort of replicating the idea with like kind of a new learning set of objects. Okay, and so that these are all sort of examples of how our attention might be guided when we encounter a new scene. Where is it that we decide to focus our attention? Well, it seems like that we have these models of the world. We have this, this unconscious inferences past experience. We've learned statistical regularities of the world and the way that our attention interacts with the scene is based on all this stored knowledge about how scenes and objects in the world tend to work. And that helps guide our attention in a new scene based on this past experience. Any questions about this contextual queuing stuff? Okay, so now we're going to talk about this idea of enhancing perceptual information. And so there's been a lot of research that shows that the suggestion that attention isn't a spotlight necessarily. So if the spotlight metaphor of attention is this idea that it's, the spotlight is choosing what information to process. And so you can extend that spotlight metaphor too, zoom lens metaphor. And so not only is, is this spotlight selecting what to process, but by selecting that information, it's also enhancing our visual perceptual processing of that stimuli. And so I'll show you some studies that have suggested that this might be the case. Alright, so first just, I'm going to show some sort of basic, basic attention research. So does any rectangle change? So you're going to be presented with one circle of differently oriented rectangles. It's going to disappear and then reappear. Maybe one of them changed orientation. Maybe one of them didn't. Okay. Here we go. Change or not. Why do people can tell bottom-right? Yeah. Let's try it again. How about now? Did you catch that one? So go back and do it one more time. So you gotta Q this time of where to focus your attention. And probably very intuitively, in this situation yet with the training wheels, as A1 says, they, people are much more accurate, right? And this seems like a really obvious finding. And it probably is, but it There were early experiments that actually demonstrated this effect. That seems very intuitive to us that information processing is more effective at the place where attention is directed. To me. It seems so intuitive that these, these studies seem almost kinda pointless, but that they were these first empirical demonstrations of what you just noticed intuitively. And they lead to some more interesting findings. So first study to really demonstrate this was in 1978. Actually, they had people look at this fixation point. There was a queue about where a target would appear. And the queue can either be valid or invalid. So valid meant that acute people to where the target was actually able, was actually going to appear and invalid QM at the arrow pointed in the opposite direction. And probably pretty intuitively, reaction times are very influenced by this. So when it's a valid cue, people are much faster to react to the target than when it's an invalid Q. So this back here would be a situation of a valid queue, right? That is actually the rectangle that's orientation changed. If I had pointed to a different rectangle, that would have slow or impaired your accuracy pretty dramatically. So this is just a basic feature that even when, even when you're not, you're not moving your eyes, you're paying covert attention. But when your attention is cued to a location, you're going to be faster and more accurate at processing information in that location. Again, it seems very intuitive, but this is a very famous groundbreaking study to actually empirically demonstrate this. And this I think is a, is a very interesting extension of this sort of work. And this is referred to as the same object advantage. And so what this study suggests is that our spotlight of attention isn't necessarily spatial in, in that like it. It's not necessarily a spatial location, but it can be to an entire object. So what they did in this study is you have, so look at the stimulus on the right here. You have these two vertical bars. And the task is to respond to the where the cue is. So press a, B, C, or D. Now, if you're queued in a is queued, you're gonna be really fast to respond to a. But what happens is if a is queued, but then what you're actually supposed to respond to is B. You'll still be faster when a is cued to respond to B. Because B, the logic is that it's part of that same object. So a was cued. You're supposed to say B. You're supposed to press B, you're faster when you were Q to that same object, but you're not faster when c is what you're supposed to respond. And the interesting thing is that c is the same spatial distance from a. So this suggest that it's not just spatial location, it's not just something as close to the area that you're attending to. But the fact that it's actually part of the same object seems to matter. Are you guys all in La Jolla were experiencing this from earthquake or something? That I thought. Did you have a question? Oh, sorry. It was an accident. I actually don't have a question though. Sure. Yeah. So as part of the thing of it being the same, objectives also have to do with the fact that like our minds automatically will say in our heads like AB, CD versus just because alphabetical order as a part of that tail incidence it's labeled that way that also is faster. That is a really good point given how this experiment is presented. I don't think that this paper would have passed review if that's actually the way that they did it. I think that this, this little didactic is just for sort of understanding how the experiment was done. I'm not sure if they actually use the letters a, B, C, and D. But yeah, I agree that would've been a big problem for sure. Another thing too, is like the orientation of the bars. Like I'm sure. Like it could be that you want to split things left into your left and right visual field. I would venture to guess that in this experiment they also had a different condition where the lines were vertically oriented also. But yeah, great question, good thinking. Okay, so class is over, it's 249. We'll stop here and continue talking about this on Friday. And is the trawling station running now? It's not there. There. They're just starting to like make the station so they can actually go up to the trolley. Okay. But a part of building that trolley and balls like cement and it doesn't fall out of there like machine. So they need to bang it. A bunch of pieces are going to be like a permanent thing. The trolleys and I both see questions about quiz for yeah, hold off on taking was formed to look at it right now and then I'll decide what to do. I'll probably just extend the deadline rather than change it. So yeah, I think what I'll end up announcing is I'll figure out what point in what lecture quiz material covers and then make an announcement that like, Don't take the quiz until you've gotten to this point in the material. If you already took it, send me an email and we'll figure out what to do. Alright. And I office hours today at three, stop by if again, I'm behind on emails to the most effective thing to do if you're waiting for something is to pray, Come to my office hours, if you can tell me to do whatever the thing is. I have a question. So I forgot to take quizzes, but I just took, hey, right before class and I got 8.5, that is nine. So I don't know what that would be counting. Yes. Yes, it will be counted. I reopen it because there was some issues with the way the syllabus. I've never done this before and I think this is why I've set the due date, set it to close at a certain date. But according to the syllabus, which I'd forgotten, I'd built into the syllabus, is that you get 10% taken off forever, like day it's late or something. But what happened is I closed it and then people couldn't do that. And so rather than deal with dealing with a penalty, I just reopened it. So if you're able to take it it I think it'll automatically deduct those points to 8.5 out of nine, maybe that was a deduction. No, I I had like half of the mistakes, I think. Okay, great. So, you know, penalty was applied. Perfect. And penalty would be a plane. Now, I think it happens. I think it happens right away. Oh, yeah. I turn that off when I reopen the quiz just because there's so much confusion about it. Yeah, it will come. A guy descending extra credit to me. The answer in the chat, but I'm just going to go into Twitter. You can get like maybe there's like a list of topics that being Kafir In, in each quiz. So, yeah, that's a good idea. To get an idea, we can get a head off like lists of the top is that it is better to prepare as well. Yeah, that's a good idea. And then I won't have to be so close. We wait to the when it was covered. I'm going to try to just stick to only material from the previous week, but a list of topics in addition to that couldn't hurt. I'll, I'll post that for this week. Have you taken the quiz yet? Well, you know, you had it though. Okay, so yeah, all, all post the list of topics or at least what the last lecture was. The fourth, the first and last lecture was when I send the announcement of less. Sure. Any other questions? All right, see you as a home and error wins.